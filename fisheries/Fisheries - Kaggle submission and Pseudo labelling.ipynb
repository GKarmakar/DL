{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisheries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG + BN + Multi OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7bc90d7cc2a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named utils"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path = \"data/fish/sample/\"\n",
    "path = \"/home/ubuntu/data/fisheries/\"\n",
    "batch_size=64\n",
    "batches = get_batches(path+'train', batch_size=batch_size, shuffle=False)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "test_batches = get_batches(path+'test', batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre compute conv features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split Conv layers and create conv model\n",
    "conv_layers,fc_layers = split_at_last(model, Convolution2D)\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict(trn)\n",
    "conv_val_feat = conv_model.predict(val)\n",
    "conv_test_feat = conv_model.predict(test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array(path+'results/conv_feat.dat', conv_feat)\n",
    "save_array(path+'results/conv_test_feat.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 14, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3277, 512, 14, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stick a few BN and Dense layers and have multiple output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MaxP+BN+ DO+Flat+Dense+ (BN+DO+Dense)+(BN+DO+Dense(box)+Dense(fish))\n",
    "p=0.5\n",
    "inp = Input(shape=conv_layers[-1].output_shape[1:])\n",
    "x = MaxPooling2D()(inp)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(p)(x)\n",
    "x_bb = Dense(4, name='bb')(x)\n",
    "x_fish = Dense(8, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model([inp], [x_bb, x_fish])\n",
    "model.compile(Adam(lr=0.001), loss=['mse', 'categorical_crossentropy'], metrics=['accuracy'],\n",
    "             loss_weights=[.001, 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load hand labelled bounding box training data and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']\n",
    "bb_json = {}\n",
    "for c in anno_classes:\n",
    "    j = json.load(open('{}anno/{}_labels.json'.format(path, c), 'r'))\n",
    "    #Create a map with image name as key and height/width,x,y as values \n",
    "    #and ordered by size of the box\n",
    "    #Note: Some filenames are absolute, so clean them up\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'class': u'rect',\n",
       " u'height': 109.98000000000036,\n",
       " u'width': 201.6300000000006,\n",
       " u'x': 208.6800000000006,\n",
       " u'y': 359.55000000000103}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_json['img_05166.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add empty boxes for images which do not have fishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the actual file name\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create an indexed list of names?\n",
    "file2idx = {o:i for i,o in enumerate(raw_filenames)}\n",
    "val_file2idx = {o:i for i,o in enumerate(raw_val_filenames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty_bbox = {'height': 0., 'width': 0., 'x': 0., 'y': 0.}\n",
    "for f in raw_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_val_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize it to 224x224 image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb, size):\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    conv_x = (224. / size[0])\n",
    "    conv_y = (224. / size[1])\n",
    "    bb[0] = bb[0]*conv_y\n",
    "    bb[1] = bb[1]*conv_x\n",
    "    bb[2] = max(bb[2]*conv_x, 0)\n",
    "    bb[3] = max(bb[3]*conv_y, 0)\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = [PIL.Image.open(path+'train/'+f).size for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_bbox = np.stack([convert_bb(bb_json[f], s) for f,s in zip(raw_filenames, sizes)], \n",
    "                   ).astype(np.float32)\n",
    "val_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_val_filenames, raw_val_sizes)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3277 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "3277/3277 [==============================] - 2s - loss: 6.3012 - bb_loss: 5040.5669 - dense_13_loss: 1.2606 - bb_acc: 0.4275 - dense_13_acc: 0.6375 - val_loss: 5.5811 - val_bb_loss: 4634.0021 - val_dense_13_loss: 0.9471 - val_bb_acc: 0.5600 - val_dense_13_acc: 0.8140\n",
      "Epoch 2/3\n",
      "3277/3277 [==============================] - 1s - loss: 5.1448 - bb_loss: 4781.7002 - dense_13_loss: 0.3631 - bb_acc: 0.5288 - dense_13_acc: 0.9008 - val_loss: 4.6197 - val_bb_loss: 4282.2805 - val_dense_13_loss: 0.3374 - val_bb_acc: 0.5420 - val_dense_13_acc: 0.9380\n",
      "Epoch 3/3\n",
      "3277/3277 [==============================] - 1s - loss: 4.5522 - bb_loss: 4376.1161 - dense_13_loss: 0.1761 - bb_acc: 0.5590 - dense_13_acc: 0.9445 - val_loss: 4.0888 - val_bb_loss: 3853.0484 - val_dense_13_loss: 0.2358 - val_bb_acc: 0.5640 - val_dense_13_acc: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f028dfdd190>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(conv_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3277 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "3277/3277 [==============================] - 2s - loss: 3.9616 - bb_loss: 3836.2062 - dense_13_loss: 0.1254 - bb_acc: 0.5816 - dense_13_acc: 0.9628 - val_loss: 3.6075 - val_bb_loss: 3367.5271 - val_dense_13_loss: 0.2399 - val_bb_acc: 0.6180 - val_dense_13_acc: 0.9620\n",
      "Epoch 2/3\n",
      "3277/3277 [==============================] - 1s - loss: 3.2960 - bb_loss: 3202.8387 - dense_13_loss: 0.0932 - bb_acc: 0.6079 - dense_13_acc: 0.9735 - val_loss: 3.1080 - val_bb_loss: 2849.2987 - val_dense_13_loss: 0.2587 - val_bb_acc: 0.6280 - val_dense_13_acc: 0.9520\n",
      "Epoch 3/3\n",
      "3277/3277 [==============================] - 1s - loss: 2.5242 - bb_loss: 2466.3798 - dense_13_loss: 0.0578 - bb_acc: 0.6430 - dense_13_acc: 0.9835 - val_loss: 2.2514 - val_bb_loss: 2024.4412 - val_dense_13_loss: 0.2269 - val_bb_acc: 0.6620 - val_dense_13_acc: 0.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f029151e790>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(conv_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3277 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "3277/3277 [==============================] - 2s - loss: 1.7986 - bb_loss: 1742.1811 - dense_13_loss: 0.0565 - bb_acc: 0.6771 - dense_13_acc: 0.9847 - val_loss: 1.6382 - val_bb_loss: 1383.1369 - val_dense_13_loss: 0.2551 - val_bb_acc: 0.7020 - val_dense_13_acc: 0.9560\n",
      "Epoch 2/3\n",
      "3277/3277 [==============================] - 1s - loss: 1.1535 - bb_loss: 1100.6106 - dense_13_loss: 0.0529 - bb_acc: 0.7202 - dense_13_acc: 0.9854 - val_loss: 1.1818 - val_bb_loss: 923.7057 - val_dense_13_loss: 0.2581 - val_bb_acc: 0.7420 - val_dense_13_acc: 0.9600\n",
      "Epoch 3/3\n",
      "3277/3277 [==============================] - 1s - loss: 0.7354 - bb_loss: 681.8768 - dense_13_loss: 0.0535 - bb_acc: 0.7711 - dense_13_acc: 0.9857 - val_loss: 0.8161 - val_bb_loss: 578.8653 - val_dense_13_loss: 0.2373 - val_bb_acc: 0.7960 - val_dense_13_acc: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f028dfddad0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(conv_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3277 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "3277/3277 [==============================] - 2s - loss: 0.3070 - bb_loss: 278.1977 - dense_13_loss: 0.0288 - bb_acc: 0.7968 - dense_13_acc: 0.9915 - val_loss: 0.6512 - val_bb_loss: 365.4737 - val_dense_13_loss: 0.2858 - val_bb_acc: 0.8200 - val_dense_13_acc: 0.9600\n",
      "Epoch 2/3\n",
      "3277/3277 [==============================] - 1s - loss: 0.2889 - bb_loss: 262.5483 - dense_13_loss: 0.0264 - bb_acc: 0.8007 - dense_13_acc: 0.9924 - val_loss: 0.6311 - val_bb_loss: 358.0238 - val_dense_13_loss: 0.2731 - val_bb_acc: 0.8300 - val_dense_13_acc: 0.9580\n",
      "Epoch 3/3\n",
      "3277/3277 [==============================] - 1s - loss: 0.2813 - bb_loss: 255.7603 - dense_13_loss: 0.0255 - bb_acc: 0.8050 - dense_13_acc: 0.9921 - val_loss: 0.6233 - val_bb_loss: 360.0164 - val_dense_13_loss: 0.2632 - val_bb_acc: 0.8180 - val_dense_13_acc: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f028d0b5c90>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(conv_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/multi_output.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results on training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(conv_val_feat, [val_bbox, val_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import simplejson\n",
    "with open(path+'results/multi_op.results', 'wb') as fp:\n",
    "    simplejson.dump(results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions on test set and generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(conv_test_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/7, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.90)\n",
    "subm_name = path+'results/multi_op.gz'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_06237.jpg</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.647696</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.059853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_06893.jpg</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02082.jpg</td>\n",
       "      <td>0.233902</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.759288</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_06261.jpg</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_03628.jpg</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_06237.jpg  0.266700  0.647696  0.014286  0.014286  0.014286  0.015809   \n",
       "1  img_06893.jpg  0.900000  0.014286  0.014286  0.014286  0.014286  0.014286   \n",
       "2  img_02082.jpg  0.233902  0.014286  0.014286  0.014286  0.759288  0.014286   \n",
       "3  img_06261.jpg  0.900000  0.014286  0.014286  0.014286  0.014286  0.014286   \n",
       "4  img_03628.jpg  0.900000  0.014286  0.014286  0.014286  0.014286  0.014286   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.014286  0.059853  \n",
       "1  0.014286  0.014286  \n",
       "2  0.014286  0.014286  \n",
       "3  0.014286  0.014286  \n",
       "4  0.014286  0.014286  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'image', raw_test_filenames)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/home/ubuntu/data/fisheries/results/multi_op.gz' target='_blank'>/home/ubuntu/data/fisheries/results/multi_op.gz</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/data/fisheries/results/multi_op.gz"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batches = gen.flow(conv_feat, trn_labels, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batches = gen.flow(conv_val_feat, val_labels, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = gen.flow(conv_feat, trn_labels, batch_size=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mi = MixIterator([batches, test_batches, val_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The model expects 2 input arrays, but only received one array. Found: array with shape (500, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-2887b4960934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_val_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1388\u001b[0m                                 \u001b[0;34m'(val_x, val_y, val_sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m                                 'or (val_x, val_y). Found: ' + str(validation_data))\n\u001b[0;32m-> 1390\u001b[0;31m             \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    963\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m    966\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m    967\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m     74\u001b[0m             raise Exception('The model expects ' + str(len(names)) +\n\u001b[1;32m     75\u001b[0m                             \u001b[0;34m' input arrays, but only received one array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                             'Found: array with shape ' + str(data.shape))\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The model expects 2 input arrays, but only received one array. Found: array with shape (500, 8)"
     ]
    }
   ],
   "source": [
    "model.fit_generator(mi, mi.N, nb_epoch=8, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
